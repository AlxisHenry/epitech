# ğŸ—£ï¸ Service Speech-to-Text (STT)

Le projet intÃ¨gre un service de reconnaissance vocale (STT) pour convertir les requÃªtes vocales des utilisateurs en texte exploitable par le pipeline NLP.

L'application mobile, crÃ©Ã©e avec React Native, permet Ã  l'utilisateur de saisir sa requÃªte de trajet en train via la voix. Le service STT utilise la librairie `expo-speech-recognition` pour capturer et transcrire la parole en texte, qui est ensuite envoyÃ© Ã  l'API Laravel qui s'occupe de l'orchestration des services NLP et Pathfinder.

### FonctionnalitÃ©s clÃ©s du service STT :
- **Transcription en temps rÃ©el :** La transcription de la parole est effectuÃ©e en temps rÃ©el, offrant une expÃ©rience utilisateur fluide.
- **Support multilingue :** Bien que le projet soit principalement en franÃ§ais, la librairie utilisÃ©e supporte plusieurs langues, permettant une future extension Ã  d'autres marchÃ©s.
- **IntÃ©gration transparente :** Le service STT est intÃ©grÃ© de maniÃ¨re transparente dans le pipeline de traitement, assurant que les requÃªtes vocales sont correctement formatÃ©es pour le service NLP.
- **Gestion des erreurs :** Le service inclut des mÃ©canismes de gestion des erreurs pour traiter les cas oÃ¹ la transcription pourrait Ãªtre incorrecte ou incomplÃ¨te, garantissant ainsi une robustesse accrue du systÃ¨me global.


# ğŸ“š GÃ©nÃ©ration et structuration du dataset
## 1. Objectif
Lâ€™objectif du dataset est dâ€™entraÃ®ner un systÃ¨me NLP capable de :

DÃ©terminer si une phrase correspond Ã  une demande de trajet en train (is_valid)
Extraire la ville de dÃ©part
Extraire la ville dâ€™arrivÃ©e
Le dataset simule des requÃªtes rÃ©alistes en franÃ§ais, incluant des variations linguistiques et du bruit contrÃ´lÃ©.

## 2. MÃ©thodologie de gÃ©nÃ©ration
Le corpus a Ã©tÃ© gÃ©nÃ©rÃ© de maniÃ¨re synthÃ©tique Ã  lâ€™aide :

dâ€™un script Python de gÃ©nÃ©ration contrÃ´lÃ©e
dâ€™un ensemble de templates linguistiques dÃ©finis par nos soins
dâ€™un modÃ¨le dâ€™IA gÃ©nÃ©rative utilisÃ© comme outil dâ€™augmentation linguistique
Utilisation dâ€™une IA gÃ©nÃ©rative
Lâ€™IA gÃ©nÃ©rative a Ã©tÃ© utilisÃ©e dans une dÃ©marche de prompt engineering structurÃ©.

Nous avons fourni des instructions prÃ©cises concernant :

les structures syntaxiques attendues
la prÃ©sence obligatoire dâ€™une origine et dâ€™une destination
lâ€™inclusion de phrases invalides
lâ€™introduction de bruit linguistique
la diversitÃ© des formulations
Lâ€™IA nâ€™a pas gÃ©nÃ©rÃ© librement du texte : elle a Ã©tÃ© guidÃ©e par un cahier des charges prÃ©cis afin de produire des phrases exploitables pour lâ€™apprentissage supervisÃ©.

Les annotations finales (spans caractÃ¨res, entitÃ©s canoniques et surfaces) ont Ã©tÃ© gÃ©nÃ©rÃ©es et vÃ©rifiÃ©es programmaticalement afin de garantir la cohÃ©rence et la reproductibilitÃ© du dataset.

## 3. Structure des phrases
### 3.1 RequÃªtes valides simples
Exemples :

Je voudrais aller de Toulouse Ã  Bordeaux
Je veux un billet de train de Paris Ã  Lyon
Trajet Strasbourg Marseille
Il y a-t-il des trains de Nantes Ã  Montaigu ?
### 3.2 RequÃªtes avec structures variÃ©es
Depuis Paris, je veux aller Ã  Strasbourg
Je souhaite me rendre Ã  Lyon depuis Marseille
Paris Toulouse
Paris -> Toulouse
### 3.3 Phrases invalides
Exemples :

Bonjour
Quel temps fait-il Ã  Paris ?
Je veux du caca
Je veux un billet
Ces phrases permettent dâ€™entraÃ®ner la classification is_valid.

## 4. Injection de bruit (data augmentation)
Afin dâ€™amÃ©liorer la robustesse du modÃ¨le, du bruit contrÃ´lÃ© a Ã©tÃ© introduit :

Variations de casse (paris, PARIS, PaRiS)
Suppression dâ€™accents (OrlÃ©ans â†’ Orleans)
Variation tirets / espaces (Saint-Denis â†’ Saint Denis)
Fautes de frappe simulÃ©es (Nantes â†’ Nates, Paris â†’ Parais)
Ordre syntaxique variable
Environ 30 % des phrases contiennent au moins une forme de bruit linguistique.

## 5. Annotation des donnÃ©es
Chaque phrase valide contient :

departure_canonical
arrival_canonical
departure_surface
arrival_surface
departure_span_start
departure_span_end
arrival_span_start
arrival_span_end
Les spans caractÃ¨res permettent dâ€™identifier prÃ©cisÃ©ment la position des entitÃ©s dans le texte.

Exemple
Je veux aller de Strasbourg Ã  Marseille
departure_span_start = 17 arrival_span_start = 30

Lâ€™utilisation des spans garantit :

aucune perte dâ€™exemples valides
une annotation cohÃ©rente
un apprentissage fiable du modÃ¨le NER
## 6. Jeux de donnÃ©es gÃ©nÃ©rÃ©s
Dataset 10 000 phrases (version initiale)
Ã‰lÃ©ment	Valeur
Nombre total de phrases	10 000
Phrases valides	~82 %
Phrases invalides	~18 %
Annotation	DEP / ARR + spans
Ce dataset a permis de valider le pipeline complet (classification + NER).

Dataset 100 000 phrases (version augmentÃ©e)
Ã‰lÃ©ment	Valeur
Nombre total de phrases	100 000
SchÃ©ma	Identique au dataset 10k
Objectif	AmÃ©liorer la gÃ©nÃ©ralisation
Ce dataset a permis dâ€™augmenter fortement la diversitÃ© linguistique et de rÃ©duire lâ€™overfitting.

## 7. Justification des choix
Lâ€™approche synthÃ©tique prÃ©sente plusieurs avantages :

ContrÃ´le total des annotations
ReproductibilitÃ© complÃ¨te
DiversitÃ© linguistique Ã©levÃ©e
GÃ©nÃ©ration rapide de volumes importants
PossibilitÃ© dâ€™introduire des cas ambigus et du bruit contrÃ´lÃ©
## 8. Limites
DonnÃ©es synthÃ©tiques (non issues dâ€™utilisateurs rÃ©els)
Possible biais liÃ© aux templates
Liste de villes contrÃ´lÃ©e et non exhaustive
Ces limites pourront Ãªtre adressÃ©es par lâ€™intÃ©gration future de donnÃ©es rÃ©elles.

RÃ©sumÃ©
Nous avons utilisÃ© une approche hybride combinant gÃ©nÃ©ration programmatique et IA gÃ©nÃ©rative dans une dÃ©marche de prompt engineering structurÃ© afin de produire un dataset contrÃ´lÃ©, annotÃ© et adaptÃ© Ã  notre tÃ¢che NLP.

# ğŸ§  NLP Service â€“ Scikit-learn + CRF NER

Extraction de villes de dÃ©part et dâ€™arrivÃ©e depuis une phrase utilisateur.

---

## ğŸ¯ Objectif

Ce service NLP permet dâ€™extraire automatiquement :

- La ville de dÃ©part  
- La ville dâ€™arrivÃ©e  
- DÃ©terminer si la phrase est une demande de trajet valide (`is_valid`)  

Ã  partir dâ€™une phrase utilisateur saisie dans un chatbot.

### Exemple

EntrÃ©e :

Je veux aller de Paris Ã  Lyon demain matin  

Sortie :

is_valid = True  
departure = Paris  
arrival = Lyon  

Le modÃ¨le repose sur une approche classique Machine Learning combinant :

- Une classification binaire (valide / invalide)  
- Un modÃ¨le NER basÃ© sur un Conditional Random Field (CRF)

---

## ğŸ— Architecture NLP

Dataset CSV  
â†“  
Split train / val / test  
â†“  
Classification (is_valid)  
- TF-IDF  
- Logistic Regression  
â†“  
NER  
- Tokenisation  
- Feature engineering  
- CRF  
â†“  
Ã‰valuation  
â†“  
Sauvegarde modÃ¨les  
â†“  
Service Predictor  

---

## ğŸ“¦ Dataset

### Format utilisÃ©

Chaque ligne du dataset contient :

| Colonne | Description |
|----------|-------------|
| text | Phrase utilisateur |
| departure_span_start | Index dÃ©but ville dÃ©part |
| departure_span_end | Index fin ville dÃ©part |
| arrival_span_start | Index dÃ©but ville arrivÃ©e |
| arrival_span_end | Index fin ville arrivÃ©e |
| is_valid | 1 si phrase valide |

Les spans permettent de gÃ©nÃ©rer automatiquement les labels BIO pour lâ€™entraÃ®nement du modÃ¨le NER.

---

## âœ‚ï¸ Split des donnÃ©es

Script : split_chargeur.py  

RÃ©partition :

- 70 % Train  
- 15 % Validation  
- 15 % Test  

CaractÃ©ristiques :

- Stratification sur `is_valid`  
- random_state = 42  

---

## ğŸ¤– ModÃ¨les utilisÃ©s

### Classification â€“ is_valid

Pipeline :

TfidfVectorizer  
â†’ LogisticRegression  

Pourquoi ce choix ?

- ModÃ¨le simple et rapide  
- TrÃ¨s performant sur texte court  
- Faible coÃ»t computationnel  
- Suffisant pour une tÃ¢che binaire  

---

### NER â€“ Conditional Random Field (CRF)

ImplÃ©mentation : sklearn-crfsuite  

Pourquoi un CRF ?

- AdaptÃ© aux tÃ¢ches sÃ©quentielles  
- Prend en compte le contexte des tokens voisins  
- LÃ©ger comparÃ© aux Transformers  
- InterprÃ©table  
- Suffisant pour un vocabulaire contrÃ´lÃ©  

---

## ğŸ· StratÃ©gie dâ€™annotation (BIO)

Labels utilisÃ©s :

O  
B-DEP  
I-DEP  
B-ARR  
I-ARR  

Signification :

- B- : dÃ©but dâ€™une entitÃ©  
- I- : continuation dâ€™une entitÃ©  
- O : hors entitÃ©  

Exemple :

Phrase :  
Je vais de Paris Ã  Lyon  

Je â†’ O  
vais â†’ O  
de â†’ O  
Paris â†’ B-DEP  
Ã  â†’ O  
Lyon â†’ B-ARR  

---

## ğŸ” Tokenisation et Feature Engineering

Pour chaque token, nous extrayons :

- Le token en minuscule  
- Le token original  
- Longueur du token  
- Si le token est en majuscule  
- Si le token commence par une majuscule  
- Si le token contient un tiret  
- Si le token est numÃ©rique  
- Le token prÃ©cÃ©dent  
- Le token suivant  

Cette approche permet au CRF dâ€™apprendre des motifs comme :

- de + VILLE  
- depuis + VILLE  
- VILLE Ã  VILLE  

---

## âš™ï¸ EntraÃ®nement

### Classification

- TfidfVectorizer  
- LogisticRegression (max_iter = 1000)  

### CRF â€“ HyperparamÃ¨tres

| ParamÃ¨tre | Valeur |
|------------|--------|
| algorithm | lbfgs |
| c1 | 0.1 |
| c2 | 0.1 |
| max_iterations | 100 |
| all_possible_transitions | True |

Signification :

- c1 â†’ rÃ©gularisation L1  
- c2 â†’ rÃ©gularisation L2  
- all_possible_transitions â†’ autorise toutes les transitions BIO possibles  

---

## ğŸ“Š MÃ©triques

### Classification

- Accuracy  
- Precision  
- Recall  
- F1-score  

### NER

- Accuracy dÃ©part  
- Accuracy arrivÃ©e  
- Exact match (DEP + ARR corrects)  

Pourquoi exact match ?

Car lâ€™objectif mÃ©tier exige que les deux villes soient correctes simultanÃ©ment.

---

## ğŸ“Š Ã‰valuation du modÃ¨le

### 1. Protocole dâ€™Ã©valuation

Lâ€™Ã©valuation du modÃ¨le a Ã©tÃ© rÃ©alisÃ©e sur le **jeu de test**, reprÃ©sentant **15 %** du dataset total.

Ce jeu de test est :

- Strictement sÃ©parÃ© des donnÃ©es dâ€™entraÃ®nement
- Jamais vu pendant le training
- StratifiÃ© selon la variable `is_valid`
- GÃ©nÃ©rÃ© avec un `random_state = 42` afin dâ€™assurer la reproductibilitÃ©

Lâ€™objectif de cette Ã©valuation est de mesurer :

- La performance de la classification (`is_valid`)
- La qualitÃ© de lâ€™extraction des entitÃ©s (ville de dÃ©part et ville dâ€™arrivÃ©e)

---

### 2. RÃ©sultats â€“ Classification `is_valid`

La classification binaire a Ã©tÃ© Ã©valuÃ©e Ã  lâ€™aide des mÃ©triques suivantes :

- Accuracy
- Precision
- Recall
- F1-score

#### RÃ©sultats obtenus

InsÃ©rer ici le screenshot du `classification_report` :

![Figure 1 â€“ RÃ©sultats de la classification sur le jeu de test](./screenshots/nlp_sklearn/result_train.png)

Figure 1 â€“ RÃ©sultats de la classification sur le jeu de test.

#### Analyse

Le modÃ¨le atteint une **accuracy de 1.00** sur le jeu de test.

Cela sâ€™explique par :

- Une sÃ©paration claire entre phrases valides et invalides
- Une forte cohÃ©rence du dataset synthÃ©tique
- Une tÃ¢che binaire relativement bien dÃ©finie

La prÃ©cision et le rappel sont Ã©galement Ã©quilibrÃ©s, indiquant lâ€™absence de biais significatif entre les classes.

---

### 3. RÃ©sultats â€“ Extraction des entitÃ©s (NER)

Lâ€™extraction des entitÃ©s a Ã©tÃ© Ã©valuÃ©e uniquement sur les phrases valides du jeu de test.

Les mÃ©triques suivantes ont Ã©tÃ© calculÃ©es :

- Accuracy pour la ville de dÃ©part
- Accuracy pour la ville dâ€™arrivÃ©e
- Exact match (les deux entitÃ©s correctes simultanÃ©ment)

#### RÃ©sultats obtenus

InsÃ©rer ici le screenshot des mÃ©triques NER :

![Figure 2 â€“ Performances NER (DEP/ARR) sur le jeu de test](./screenshots/nlp_sklearn/extraction_DEP_ARR.png)

Figure 2 â€“ Performances du modÃ¨le NER sur le jeu de test.

Les performances observÃ©es sont :

- DEP accuracy â‰ˆ 0.75  
- ARR accuracy â‰ˆ 0.75  
- Exact match â‰ˆ 0.58  

#### Analyse

Lâ€™extraction dâ€™entitÃ©s est significativement plus complexe que la classification binaire.

Une accuracy dâ€™environ 75 % par entitÃ© montre que :

- Le modÃ¨le apprend correctement les structures typiques telles que Â« de + VILLE Â» ou Â« VILLE Ã  VILLE Â»
- Le CRF exploite efficacement le contexte local des tokens

Cependant, lâ€™exact match (â‰ˆ 58 %) rÃ©vÃ¨le que :

- Il est plus difficile dâ€™extraire simultanÃ©ment les deux entitÃ©s correctement
- Certaines erreurs surviennent sur des formulations plus atypiques
- Le modÃ¨le peut confondre lâ€™ordre dÃ©part / arrivÃ©e dans certaines structures inversÃ©es

---

### 4. InterprÃ©tation globale

Les rÃ©sultats dÃ©montrent que :

- La classification `is_valid` est maÃ®trisÃ©e
- Lâ€™extraction NER atteint des performances satisfaisantes pour une approche lÃ©gÃ¨re sans Transformer
- Le modÃ¨le est fonctionnel et exploitable dans un contexte applicatif

Ces performances valident le choix dâ€™une architecture basÃ©e sur :

- TF-IDF + Logistic Regression pour la classification
- CRF pour lâ€™extraction sÃ©quentielle

---

### 5. Limites observÃ©es

Certaines erreurs apparaissent dans les cas suivants :

- Structures syntaxiques rares
- Formulations ambiguÃ«s
- Ordres inversÃ©s non frÃ©quents dans le dataset
- Villes peu reprÃ©sentÃ©es

Ces limites pourront Ãªtre amÃ©liorÃ©es via :

- Un enrichissement du dataset
- Une augmentation de la diversitÃ© linguistique
- Un benchmark avec un modÃ¨le Transformer (ex : CamemBERT)

---

### Conclusion de lâ€™Ã©valuation

Lâ€™Ã©valuation confirme que lâ€™architecture retenue permet :

- Une classification robuste des requÃªtes
- Une extraction fiable des entitÃ©s principales
- Une solution lÃ©gÃ¨re, rapide et reproductible

Le modÃ¨le constitue une base solide pour une application conversationnelle orientÃ©e transport.

---

## ğŸš€ Inference

Pipeline :

Phrase utilisateur  
â†“  
Classification (is_valid)  
â†“  
Si valide  
â†“  
Tokenisation  
â†“  
CRF  
â†“  
Reconstruction entitÃ©s  
â†“  
Extraction departure / arrival  

Le service supporte :

- Mode CLI  
- Mode API (FastAPI)  
- Traitement synchrone  

---

## ğŸ Conclusion

Ce service implÃ©mente une solution NER robuste en franÃ§ais basÃ©e sur une approche classique Machine Learning (TF-IDF + Logistic Regression + CRF).

Il permet :

- La dÃ©tection automatique des requÃªtes de trajet  
- Lâ€™extraction fiable des villes de dÃ©part et dâ€™arrivÃ©e  

Il constitue la brique NLP centrale du systÃ¨me.

# ğŸ§  NLP Service â€“ CamemBERT NER

Extraction de villes de dÃ©part et dâ€™arrivÃ©e depuis une phrase utilisateur.

---

## ğŸ¯ Objectif

Ce service NLP permet dâ€™extraire automatiquement :

- ğŸŸ¢ La ville de dÃ©part
- ğŸ”µ La ville dâ€™arrivÃ©e

Ã  partir dâ€™une phrase utilisateur saisie dans un chatbot.

### Exemple

EntrÃ©e :

```
Je veux aller de Paris Ã  Lyon demain matin
```

Sortie :

```
departure = Paris arrival = Lyon
```

Le modÃ¨le repose sur une approche **Named Entity Recognition (NER)** fine-tunÃ©e avec CamemBERT.

---

## ğŸ— Architecture NLP

```
Dataset CSV
â†“
Split train / val / test
â†“
Tokenisation + alignement BIO
â†“
Fine-tuning CamemBERT
â†“
Ã‰valuation (F1, Precision, Recall)
â†“
Sauvegarde modÃ¨le
â†“
Service Predictor (inference)
```

---

## ğŸ“¦ Dataset

### Format utilisÃ© (avec spans)

Chaque ligne du dataset contient :

| Colonne              | Description               |
| -------------------- | ------------------------- |
| text                 | Phrase utilisateur        |
| departure_span_start | Index dÃ©but ville dÃ©part  |
| departure_span_end   | Index fin ville dÃ©part    |
| arrival_span_start   | Index dÃ©but ville arrivÃ©e |
| arrival_span_end     | Index fin ville arrivÃ©e   |
| is_valid             | 1 si phrase valide        |

Le dataset est gÃ©nÃ©rÃ© automatiquement via ChatGPT, puis enrichi avec les positions exactes des entitÃ©s (spans).

---

## âœ‚ï¸ Split des donnÃ©es

Script : `split_chargeur.py`

RÃ©partition :

- 70% Train
- 15% Validation
- 15% Test

CaractÃ©ristiques :

- Stratification sur `is_valid`
- `random_state = 42` pour reproductibilitÃ©

---

## ğŸ¤– ModÃ¨le utilisÃ©

ModÃ¨le de base :

`camembert-base`

### Pourquoi CamemBERT ?

- PrÃ©-entraÃ®nÃ© sur un large corpus franÃ§ais
- Architecture Transformer (BERT-like)
- Performant pour le NER
- AdaptÃ© au langage conversationnel

---

## ğŸ· StratÃ©gie dâ€™annotation (BIO)

Labels utilisÃ©s :

```
O
B-DEPARTURE
I-DEPARTURE
B-ARRIVAL
I-ARRIVAL
```

![alt text](./screenshots/nlp_camembert/labels.png)

Signification :

- **B-** : dÃ©but dâ€™une entitÃ©
- **I-** : continuation dâ€™une entitÃ©
- **O** : hors entitÃ©

### Exemple

Phrase :

```
Je vais de Paris Ã  Lyon
```

| Token | Label       |
| ----- | ----------- |
| Je    | O           |
| vais  | O           |
| de    | O           |
| Paris | B-DEPARTURE |
| Ã      | O           |
| Lyon  | B-ARRIVAL   |

---

![alt text](./screenshots/nlp_camembert/bio_unvalid.png)
![alt text](./screenshots/nlp_camembert/bio_valid.png)

## ğŸ” Tokenisation et alignement

ProblÃ¨me :

CamemBERT dÃ©coupe les mots en sous-tokens.

Solution :

- Utilisation de `offset_mapping`
- Alignement des spans caractÃ¨res avec les tokens
- Attribution automatique des labels BIO

Fonction clÃ© :

```
tokenize_and_align()
```

Cela permet :

- Alignement prÃ©cis des entitÃ©s
- Gestion des sous-tokens
- CompatibilitÃ© avec HuggingFace Trainer

---

## âš™ï¸ EntraÃ®nement

HyperparamÃ¨tres :

| ParamÃ¨tre     | Valeur |
| ------------- | ------ |
| Batch size    | 8      |
| Epochs        | 5      |
| Learning rate | 2e-5   |
| Weight decay  | 0.01   |

Configuration :

- `eval_strategy = "epoch"`
- `save_strategy = "epoch"`
- `load_best_model_at_end = True`
- `metric_for_best_model = "f1"`

Le meilleur modÃ¨le est automatiquement conservÃ©.

---

## ğŸ“Š MÃ©triques

Ã‰valuation rÃ©alisÃ©e avec `seqeval`.

MÃ©triques calculÃ©es :

- Precision
- Recall
- F1-score

![alt text](./screenshots/nlp_camembert/result.png)

### Pourquoi F1-score ?

En NER :

- Precision â†’ qualitÃ© des entitÃ©s dÃ©tectÃ©es
- Recall â†’ capacitÃ© Ã  dÃ©tecter toutes les entitÃ©s
- F1 â†’ Ã©quilibre entre prÃ©cision et rappel

Le modÃ¨le est sÃ©lectionnÃ© selon la meilleure valeur de F1.

---

## ğŸ§ª Ã‰valuation

Ã€ la fin de lâ€™entraÃ®nement :

```python
trainer.evaluate(test_ds)

```

Permet de mesurer la performance sur des donnÃ©es jamais vues.

## ğŸš€ Inference

Pipeline dâ€™infÃ©rence :

```
Phrase utilisateur
   â†“
Tokenisation
   â†“
PrÃ©diction (logits)
   â†“
Argmax
   â†“
Reconstruction entitÃ©s
   â†“
Extraction departure / arrival

```

Le service supporte :

Lecture via fichier

Lecture via STDIN

Mode interactif CLI

---

![alt text](./screenshots/nlp_camembert/inference.png)

### Points forts

Fine-tuning spÃ©cifique au domaine transport

Dataset volumineux (~100k exemples)

Utilisation de spans prÃ©cis

Splits stratifiÃ©s

MÃ©triques adaptÃ©es au NER

Pipeline reproductible

---

### âš ï¸ Limites

Dataset gÃ©nÃ©rÃ© automatiquement (risque de biais)

Sensible aux formulations rares

Ne gÃ¨re pas encore :

Fautes dâ€™orthographe

Villes implicites

Multi-destinations

---

### ğŸ”® AmÃ©liorations possibles

Data augmentation

Injection de bruit (robustesse aux fautes)

EntraÃ®nement sur donnÃ©es rÃ©elles utilisateur

Early stopping

Hyperparameter tuning

Distillation vers modÃ¨le plus lÃ©ger

---

### ğŸ Conclusion

Ce service implÃ©mente une solution NER robuste en franÃ§ais basÃ©e sur CamemBERT pour extraire :

Ville de dÃ©part

Ville dâ€™arrivÃ©e

Il constitue la brique NLP centrale du chatbot et permet lâ€™extraction automatique dâ€™entitÃ©s Ã  partir de texte libre.


# ğŸ›¤ï¸ Service Pathfinder â€“ Graph Engine (Neo4j)

Calcul d'itinÃ©raire multi-critÃ¨res et modÃ©lisation topologique du rÃ©seau ferroviaire.

---

## ğŸ¯ Objectif

Le service **Pathfinder** est le cÅ“ur algorithmique du projet. Il transforme une requÃªte d'origine et de destination (extraite par le service NLP) en un itinÃ©raire optimisÃ© en s'appuyant sur une base de donnÃ©es orientÃ©e graphe.

### Exemple

**RequÃªte Cypher :**

```cypher
MATCH (start:Stop {name: "Paris"}), (end:Stop {name: "Lyon"})
CALL gds.shortestPath.dijkstra.stream('railwayGraph', {
    sourceNode: start,
    targetNode: end,
    relationshipWeightProperty: 'duration'
})
YIELD nodeIds, costs
```

**Sortie :**
`Path: Paris -> Dijon -> Lyon | Total Duration: 120 min`

---

## ğŸ— Architecture du Graphe (ModÃ©lisation GTFS)

Le moteur transforme les donnÃ©es statiques **GTFS** (*General Transit Feed Specification*) en un rÃ©seau topologique dynamique.

### Ã‰tapes d'ingestion :

1. **Normalisation UIC :** Regroupement des *StopPoints* techniques en entitÃ©s *StopAreas* (Gares) pour simplifier le graphe sans perte d'information gÃ©ographique.
2. **ModÃ¨le Spatio-Temporel :**
* **NÅ“uds (:Stop) :** ReprÃ©sentent les gares avec propriÃ©tÃ©s `name`, `uic_code`, `lat`, `lon`.
* **Relations (:RELIÃ‰_Ã€) :** Connectent deux gares si un trajet direct existe.
* **PondÃ©ration (Weighting) :** Chaque relation porte une propriÃ©tÃ© `weight` calculÃ©e dynamiquement () exprimÃ©e en minutes.

--- 

## ğŸ“¥ Source et Pipeline dâ€™Ingestion des DonnÃ©es

Le graphe est construit Ã  partir des donnÃ©es officielles SNCF publiÃ©es en open data sur le portail gouvernemental (format CSV conforme GTFS).

ğŸ“‚ Source des donnÃ©es

- Producteur : SNCF
- Publication : portail open data du gouvernement franÃ§ais
- Format : fichiers CSV
- Standard : GTFS (General Transit Feed Specification)

Les principaux fichiers exploitÃ©s :
- stops.txt
- trips.txt
- stop_times.txt
- routes.txt


### Processus de peuplement de la base

#### Extraction

Les fichiers CSV sont tÃ©lÃ©chargÃ©s puis intÃ©grÃ©s dans un pipeline dâ€™import automatisÃ©.

ProblÃ¨me rencontrÃ© :
Les volumes sont consÃ©quents (plusieurs centaines de milliers de lignes).
Un import direct via requÃªtes unitaires rendait les transactions trop lourdes.

Solution :
Import par batchs avec transactions fractionnÃ©es pour Ã©viter la saturation mÃ©moire.

#### Transformation

Les donnÃ©es GTFS brutes ne sont pas directement exploitables sous forme de graphe.

Travail effectuÃ© :
- Regroupement des points dâ€™arrÃªt techniques en entitÃ©s de gare via le code UIC
- Nettoyage des doublons et harmonisation des noms
- Calcul des durÃ©es entre deux gares Ã  partir des champs arrival_time / departure_time
- Filtrage des incohÃ©rences (durÃ©es nÃ©gatives, trajets incomplets)

DifficultÃ© principale :
Certaines gares apparaissaient sous diffÃ©rentes variantes dâ€™Ã©criture.
La normalisation par UIC a Ã©tÃ© indispensable pour garantir lâ€™unicitÃ© des nÅ“uds.

#### Changement dans Neo4j

- CrÃ©ation des nÅ“uds (:Stop) avec contrainte dâ€™unicitÃ© sur uic_code
- CrÃ©ation des relations pondÃ©rÃ©es (:RELIÃ‰_Ã€) avec propriÃ©tÃ© weight (durÃ©e en minutes)
- Indexation full-text sur name pour faciliter lâ€™interfaÃ§age avec le service NLP

Une attention particuliÃ¨re a Ã©tÃ© portÃ©e Ã  lâ€™ordre dâ€™import pour Ã©viter les ralentissements liÃ©s aux index et contraintes.


---

## ğŸ¤– Logique de Routage

Le service utilise l'algorithme de **Dijkstra** pour garantir l'optimalitÃ© du chemin.

### Pourquoi le Graphe (Neo4j) ?

* **Performance :** Contrairement au SQL qui nÃ©cessite des jointures rÃ©cursives (CTE) coÃ»teuses, Neo4j utilise le *pointer hopping*. Le moteur parcourt **+370 000 relations** en un temps constant  par saut.
* **FlexibilitÃ© :** Permet d'ajouter facilement des contraintes (ex: temps de correspondance minimal, types de trains favorisÃ©s).

### StratÃ©gie d'indexation

Pour garantir une latence minimale lors de l'infÃ©rence :

* **Constraint :** UnicitÃ© sur l'ID UIC des gares.
* **Full-text Index :** Sur la propriÃ©tÃ© `name` pour faciliter le matching avec les sorties du service NLP (gestion des majuscules/accents).

---

## âš™ï¸ Infrastructure Cloud

Le service est dÃ©ployÃ© sur **Neo4j Aura Professional** pour assurer une haute disponibilitÃ© et une scalabilitÃ© horizontale.

### Configuration du Service

Les variables d'environnement nÃ©cessaires Ã  la connexion via le driver officiel (Bolt/Neo4j+s) :

| Variable | Valeur |
| --- | --- |
| `NEO4J_URI` | `neo4j+s://f4ce75f0.databases.neo4j.io` |
| `NEO4J_USER` | `neo4j` |
| `NEO4J_PWD` | `TonNouveauMotDePasse123!` |



> [!IMPORTANT]
> **Contrainte de base :** Sur l'instance Aura, la base de donnÃ©es doit impÃ©rativement Ãªtre nommÃ©e `neo4j`. Toute tentative de connexion sur une base nommÃ©e diffÃ©remment entraÃ®nera une erreur de routage.
---

## ğŸ“Š MÃ©triques Techniques

* **Nombre de relations :** ~370 000
* **Temps moyen de rÃ©ponse :** < 15ms (recherche de chemin complexe)
* **Protocole :** Chiffrement TLS via `neo4j+s` (sÃ©curitÃ© bout-en-bout)

---

### ğŸ Conclusion

Le service **Pathfinder** convertit les prÃ©dictions textuelles en donnÃ©es concrÃ¨tes de transport. En combinant la puissance de **Dijkstra** et la flexibilitÃ© de **Neo4j**, il assure un calcul d'itinÃ©raire performant, scalable et prÃªt pour une mise en production.


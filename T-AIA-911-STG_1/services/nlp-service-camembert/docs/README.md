# ğŸ§  NLP Service â€“ CamemBERT NER

Extraction de villes de dÃ©part et dâ€™arrivÃ©e depuis une phrase utilisateur.

---

## ğŸ¯ Objectif

Ce service NLP permet dâ€™extraire automatiquement :

- ğŸŸ¢ La ville de dÃ©part
- ğŸ”µ La ville dâ€™arrivÃ©e

Ã  partir dâ€™une phrase utilisateur saisie dans un chatbot.

### Exemple

EntrÃ©e :

```
Je veux aller de Paris Ã  Lyon demain matin
```

Sortie :

```
departure = Paris arrival = Lyon
```

Le modÃ¨le repose sur une approche **Named Entity Recognition (NER)** fine-tunÃ©e avec CamemBERT.

---

## ğŸ— Architecture NLP

```
Dataset CSV
â†“
Split train / val / test
â†“
Tokenisation + alignement BIO
â†“
Fine-tuning CamemBERT
â†“
Ã‰valuation (F1, Precision, Recall)
â†“
Sauvegarde modÃ¨le
â†“
Service Predictor (inference)
```

---

# ğŸ“¦ Dataset

## Format utilisÃ© (avec spans)

Chaque ligne du dataset contient :

| Colonne              | Description               |
| -------------------- | ------------------------- |
| text                 | Phrase utilisateur        |
| departure_span_start | Index dÃ©but ville dÃ©part  |
| departure_span_end   | Index fin ville dÃ©part    |
| arrival_span_start   | Index dÃ©but ville arrivÃ©e |
| arrival_span_end     | Index fin ville arrivÃ©e   |
| is_valid             | 1 si phrase valide        |

Le dataset est gÃ©nÃ©rÃ© automatiquement via ChatGPT, puis enrichi avec les positions exactes des entitÃ©s (spans).

---

# âœ‚ï¸ Split des donnÃ©es

Script : `split_chargeur.py`

RÃ©partition :

- 70% Train
- 15% Validation
- 15% Test

CaractÃ©ristiques :

- Stratification sur `is_valid`
- `random_state = 42` pour reproductibilitÃ©

---

# ğŸ¤– ModÃ¨le utilisÃ©

ModÃ¨le de base :

`camembert-base`

### Pourquoi CamemBERT ?

- PrÃ©-entraÃ®nÃ© sur un large corpus franÃ§ais
- Architecture Transformer (BERT-like)
- Performant pour le NER
- AdaptÃ© au langage conversationnel

---

# ğŸ· StratÃ©gie dâ€™annotation (BIO)

Labels utilisÃ©s :

```
O
B-DEPARTURE
I-DEPARTURE
B-ARRIVAL
I-ARRIVAL
```

Signification :

- **B-** : dÃ©but dâ€™une entitÃ©
- **I-** : continuation dâ€™une entitÃ©
- **O** : hors entitÃ©

### Exemple

Phrase :

```
Je vais de Paris Ã  Lyon
```

| Token | Label       |
| ----- | ----------- |
| Je    | O           |
| vais  | O           |
| de    | O           |
| Paris | B-DEPARTURE |
| Ã      | O           |
| Lyon  | B-ARRIVAL   |

---

# ğŸ” Tokenisation et alignement

ProblÃ¨me :

CamemBERT dÃ©coupe les mots en sous-tokens.

Solution :

- Utilisation de `offset_mapping`
- Alignement des spans caractÃ¨res avec les tokens
- Attribution automatique des labels BIO

Fonction clÃ© :

```
tokenize_and_align()
```

Cela permet :

- Alignement prÃ©cis des entitÃ©s
- Gestion des sous-tokens
- CompatibilitÃ© avec HuggingFace Trainer

---

# âš™ï¸ EntraÃ®nement

HyperparamÃ¨tres :

| ParamÃ¨tre     | Valeur |
| ------------- | ------ |
| Batch size    | 8      |
| Epochs        | 5      |
| Learning rate | 2e-5   |
| Weight decay  | 0.01   |

Configuration :

- `eval_strategy = "epoch"`
- `save_strategy = "epoch"`
- `load_best_model_at_end = True`
- `metric_for_best_model = "f1"`

Le meilleur modÃ¨le est automatiquement conservÃ©.

---

# ğŸ“Š MÃ©triques

Ã‰valuation rÃ©alisÃ©e avec `seqeval`.

MÃ©triques calculÃ©es :

- Precision
- Recall
- F1-score

## Pourquoi F1-score ?

En NER :

- Precision â†’ qualitÃ© des entitÃ©s dÃ©tectÃ©es
- Recall â†’ capacitÃ© Ã  dÃ©tecter toutes les entitÃ©s
- F1 â†’ Ã©quilibre entre prÃ©cision et rappel

Le modÃ¨le est sÃ©lectionnÃ© selon la meilleure valeur de F1.

---

# ğŸ§ª Ã‰valuation

Ã€ la fin de lâ€™entraÃ®nement :

```python
trainer.evaluate(test_ds)

```

Permet de mesurer la performance sur des donnÃ©es jamais vues.

ğŸš€ Inference

Pipeline dâ€™infÃ©rence :

```
Phrase utilisateur
   â†“
Tokenisation
   â†“
PrÃ©diction (logits)
   â†“
Argmax
   â†“
Reconstruction entitÃ©s
   â†“
Extraction departure / arrival

```

Le service supporte :

Lecture via fichier

Lecture via STDIN

Mode interactif CLI

---

### Points forts

Fine-tuning spÃ©cifique au domaine transport

Dataset volumineux (~100k exemples)

Utilisation de spans prÃ©cis

Splits stratifiÃ©s

MÃ©triques adaptÃ©es au NER

Pipeline reproductible

---

### âš ï¸ Limites

Dataset gÃ©nÃ©rÃ© automatiquement (risque de biais)

Sensible aux formulations rares

Ne gÃ¨re pas encore :

Fautes dâ€™orthographe

Villes implicites

Multi-destinations

---

### ğŸ”® AmÃ©liorations possibles

Data augmentation

Injection de bruit (robustesse aux fautes)

EntraÃ®nement sur donnÃ©es rÃ©elles utilisateur

Early stopping

Hyperparameter tuning

Distillation vers modÃ¨le plus lÃ©ger

---

### ğŸ Conclusion

Ce service implÃ©mente une solution NER robuste en franÃ§ais basÃ©e sur CamemBERT pour extraire :

Ville de dÃ©part

Ville dâ€™arrivÃ©e

Il constitue la brique NLP centrale du chatbot et permet lâ€™extraction automatique dâ€™entitÃ©s Ã  partir de texte libre.

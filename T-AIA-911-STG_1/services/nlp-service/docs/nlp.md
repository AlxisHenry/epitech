
# ğŸ§  NLP Service â€“ Scikit-learn + CRF NER

Extraction de villes de dÃ©part et dâ€™arrivÃ©e depuis une phrase utilisateur.

---

## ğŸ¯ Objectif

Ce service NLP permet dâ€™extraire automatiquement :

- La ville de dÃ©part  
- La ville dâ€™arrivÃ©e  
- DÃ©terminer si la phrase est une demande de trajet valide (`is_valid`)  

Ã  partir dâ€™une phrase utilisateur saisie dans un chatbot.

### Exemple

EntrÃ©e :

Je veux aller de Paris Ã  Lyon demain matin  

Sortie :

is_valid = True  
departure = Paris  
arrival = Lyon  

Le modÃ¨le repose sur une approche classique Machine Learning combinant :

- Une classification binaire (valide / invalide)  
- Un modÃ¨le NER basÃ© sur un Conditional Random Field (CRF)

---

# ğŸ— Architecture NLP

Dataset CSV  
â†“  
Split train / val / test  
â†“  
Classification (is_valid)  
- TF-IDF  
- Logistic Regression  
â†“  
NER  
- Tokenisation  
- Feature engineering  
- CRF  
â†“  
Ã‰valuation  
â†“  
Sauvegarde modÃ¨les  
â†“  
Service Predictor  

---

# ğŸ“¦ Dataset

## Format utilisÃ©

Chaque ligne du dataset contient :

| Colonne | Description |
|----------|-------------|
| text | Phrase utilisateur |
| departure_span_start | Index dÃ©but ville dÃ©part |
| departure_span_end | Index fin ville dÃ©part |
| arrival_span_start | Index dÃ©but ville arrivÃ©e |
| arrival_span_end | Index fin ville arrivÃ©e |
| is_valid | 1 si phrase valide |

Les spans permettent de gÃ©nÃ©rer automatiquement les labels BIO pour lâ€™entraÃ®nement du modÃ¨le NER.

---

# âœ‚ï¸ Split des donnÃ©es

Script : split_chargeur.py  

RÃ©partition :

- 70 % Train  
- 15 % Validation  
- 15 % Test  

CaractÃ©ristiques :

- Stratification sur `is_valid`  
- random_state = 42  

---

# ğŸ¤– ModÃ¨les utilisÃ©s

## Classification â€“ is_valid

Pipeline :

TfidfVectorizer  
â†’ LogisticRegression  

Pourquoi ce choix ?

- ModÃ¨le simple et rapide  
- TrÃ¨s performant sur texte court  
- Faible coÃ»t computationnel  
- Suffisant pour une tÃ¢che binaire  

---

## NER â€“ Conditional Random Field (CRF)

ImplÃ©mentation : sklearn-crfsuite  

Pourquoi un CRF ?

- AdaptÃ© aux tÃ¢ches sÃ©quentielles  
- Prend en compte le contexte des tokens voisins  
- LÃ©ger comparÃ© aux Transformers  
- InterprÃ©table  
- Suffisant pour un vocabulaire contrÃ´lÃ©  

---

# ğŸ· StratÃ©gie dâ€™annotation (BIO)

Labels utilisÃ©s :

O  
B-DEP  
I-DEP  
B-ARR  
I-ARR  

Signification :

- B- : dÃ©but dâ€™une entitÃ©  
- I- : continuation dâ€™une entitÃ©  
- O : hors entitÃ©  

Exemple :

Phrase :  
Je vais de Paris Ã  Lyon  

Je â†’ O  
vais â†’ O  
de â†’ O  
Paris â†’ B-DEP  
Ã  â†’ O  
Lyon â†’ B-ARR  

---

# ğŸ” Tokenisation et Feature Engineering

Pour chaque token, nous extrayons :

- Le token en minuscule  
- Le token original  
- Longueur du token  
- Si le token est en majuscule  
- Si le token commence par une majuscule  
- Si le token contient un tiret  
- Si le token est numÃ©rique  
- Le token prÃ©cÃ©dent  
- Le token suivant  

Cette approche permet au CRF dâ€™apprendre des motifs comme :

- de + VILLE  
- depuis + VILLE  
- VILLE Ã  VILLE  

---

# âš™ï¸ EntraÃ®nement

## Classification

- TfidfVectorizer  
- LogisticRegression (max_iter = 1000)  

## CRF â€“ HyperparamÃ¨tres

| ParamÃ¨tre | Valeur |
|------------|--------|
| algorithm | lbfgs |
| c1 | 0.1 |
| c2 | 0.1 |
| max_iterations | 100 |
| all_possible_transitions | True |

Signification :

- c1 â†’ rÃ©gularisation L1  
- c2 â†’ rÃ©gularisation L2  
- all_possible_transitions â†’ autorise toutes les transitions BIO possibles  

---

# ğŸ“Š MÃ©triques

## Classification

- Accuracy  
- Precision  
- Recall  
- F1-score  

## NER

- Accuracy dÃ©part  
- Accuracy arrivÃ©e  
- Exact match (DEP + ARR corrects)  

Pourquoi exact match ?

Car lâ€™objectif mÃ©tier exige que les deux villes soient correctes simultanÃ©ment.

---

# ğŸ“Š Ã‰valuation du modÃ¨le

## 1. Protocole dâ€™Ã©valuation

Lâ€™Ã©valuation du modÃ¨le a Ã©tÃ© rÃ©alisÃ©e sur le **jeu de test**, reprÃ©sentant **15 %** du dataset total.

Ce jeu de test est :

- Strictement sÃ©parÃ© des donnÃ©es dâ€™entraÃ®nement
- Jamais vu pendant le training
- StratifiÃ© selon la variable `is_valid`
- GÃ©nÃ©rÃ© avec un `random_state = 42` afin dâ€™assurer la reproductibilitÃ©

Lâ€™objectif de cette Ã©valuation est de mesurer :

- La performance de la classification (`is_valid`)
- La qualitÃ© de lâ€™extraction des entitÃ©s (ville de dÃ©part et ville dâ€™arrivÃ©e)

---

## 2. RÃ©sultats â€“ Classification `is_valid`

La classification binaire a Ã©tÃ© Ã©valuÃ©e Ã  lâ€™aide des mÃ©triques suivantes :

- Accuracy
- Precision
- Recall
- F1-score

### RÃ©sultats obtenus

InsÃ©rer ici le screenshot du `classification_report` :

![Figure 1 â€“ RÃ©sultats de la classification sur le jeu de test](../screenshots/nlp_sklearn/result_train.png)

Figure 1 â€“ RÃ©sultats de la classification sur le jeu de test.

### Analyse

Le modÃ¨le atteint une **accuracy de 1.00** sur le jeu de test.

Cela sâ€™explique par :

- Une sÃ©paration claire entre phrases valides et invalides
- Une forte cohÃ©rence du dataset synthÃ©tique
- Une tÃ¢che binaire relativement bien dÃ©finie

La prÃ©cision et le rappel sont Ã©galement Ã©quilibrÃ©s, indiquant lâ€™absence de biais significatif entre les classes.

---

## 3. RÃ©sultats â€“ Extraction des entitÃ©s (NER)

Lâ€™extraction des entitÃ©s a Ã©tÃ© Ã©valuÃ©e uniquement sur les phrases valides du jeu de test.

Les mÃ©triques suivantes ont Ã©tÃ© calculÃ©es :

- Accuracy pour la ville de dÃ©part
- Accuracy pour la ville dâ€™arrivÃ©e
- Exact match (les deux entitÃ©s correctes simultanÃ©ment)

### RÃ©sultats obtenus

InsÃ©rer ici le screenshot des mÃ©triques NER :

![Figure 2 â€“ Performances NER (DEP/ARR) sur le jeu de test](../screenshots/nlp_sklearn/extraction_DEP_ARR.png)

Figure 2 â€“ Performances du modÃ¨le NER sur le jeu de test.

Les performances observÃ©es sont :

- DEP accuracy â‰ˆ 0.75  
- ARR accuracy â‰ˆ 0.75  
- Exact match â‰ˆ 0.58  

### Analyse

Lâ€™extraction dâ€™entitÃ©s est significativement plus complexe que la classification binaire.

Une accuracy dâ€™environ 75 % par entitÃ© montre que :

- Le modÃ¨le apprend correctement les structures typiques telles que Â« de + VILLE Â» ou Â« VILLE Ã  VILLE Â»
- Le CRF exploite efficacement le contexte local des tokens

Cependant, lâ€™exact match (â‰ˆ 58 %) rÃ©vÃ¨le que :

- Il est plus difficile dâ€™extraire simultanÃ©ment les deux entitÃ©s correctement
- Certaines erreurs surviennent sur des formulations plus atypiques
- Le modÃ¨le peut confondre lâ€™ordre dÃ©part / arrivÃ©e dans certaines structures inversÃ©es

---

## 4. InterprÃ©tation globale

Les rÃ©sultats dÃ©montrent que :

- La classification `is_valid` est maÃ®trisÃ©e
- Lâ€™extraction NER atteint des performances satisfaisantes pour une approche lÃ©gÃ¨re sans Transformer
- Le modÃ¨le est fonctionnel et exploitable dans un contexte applicatif

Ces performances valident le choix dâ€™une architecture basÃ©e sur :

- TF-IDF + Logistic Regression pour la classification
- CRF pour lâ€™extraction sÃ©quentielle

---

## 5. Limites observÃ©es

Certaines erreurs apparaissent dans les cas suivants :

- Structures syntaxiques rares
- Formulations ambiguÃ«s
- Ordres inversÃ©s non frÃ©quents dans le dataset
- Villes peu reprÃ©sentÃ©es

Ces limites pourront Ãªtre amÃ©liorÃ©es via :

- Un enrichissement du dataset
- Une augmentation de la diversitÃ© linguistique
- Un benchmark avec un modÃ¨le Transformer (ex : CamemBERT)

---

## Conclusion de lâ€™Ã©valuation

Lâ€™Ã©valuation confirme que lâ€™architecture retenue permet :

- Une classification robuste des requÃªtes
- Une extraction fiable des entitÃ©s principales
- Une solution lÃ©gÃ¨re, rapide et reproductible

Le modÃ¨le constitue une base solide pour une application conversationnelle orientÃ©e transport.

---

# ğŸš€ Inference

Pipeline :

Phrase utilisateur  
â†“  
Classification (is_valid)  
â†“  
Si valide  
â†“  
Tokenisation  
â†“  
CRF  
â†“  
Reconstruction entitÃ©s  
â†“  
Extraction departure / arrival  

Le service supporte :

- Mode CLI  
- Mode API (FastAPI)  
- Traitement synchrone  

---

# ğŸ Conclusion

Ce service implÃ©mente une solution NER robuste en franÃ§ais basÃ©e sur une approche classique Machine Learning (TF-IDF + Logistic Regression + CRF).

Il permet :

- La dÃ©tection automatique des requÃªtes de trajet  
- Lâ€™extraction fiable des villes de dÃ©part et dâ€™arrivÃ©e  

Il constitue la brique NLP centrale du systÃ¨me.
{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    folder_name = \"Array224\"\n",
    "\n",
    "    modele_path = \"model224.pkl\"\n",
    "\n",
    "    with open(modele_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    x_train = np.load(f'{folder_name}/x_train.npy')\n",
    "    y_train = np.load(f'{folder_name}/y_train.npy')\n",
    "    x_test = np.load(f'{folder_name}/x_test.npy')\n",
    "    y_test = np.load(f'{folder_name}/y_test.npy')\n",
    "    x_val = np.load(f'{folder_name}/x_val.npy')\n",
    "    y_val = np.load(f'{folder_name}/y_val.npy')\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Temps d'entraînement : {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "    with open(modele_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"Précision sur le set de test :\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    y_eval_pred = model.predict(x_val)\n",
    "    print(\"Précision sur le set d'évaluation :\", accuracy_score(y_val, y_eval_pred))\n",
    "\n",
    "    while model.max_iter < 3000:\n",
    "\n",
    "        model.max_iter += 100\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "        print(\"Précision sur le set de test :\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "        y_eval_pred = model.predict(x_val)\n",
    "        print(\"Précision sur le set d'évaluation :\", accuracy_score(y_val, y_eval_pred))"
   ],
   "id": "6cfc8813dceeee48"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
